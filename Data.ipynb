{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38aa086c-b6ea-49b4-b17f-9f19bd962fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T09:48:39.403373Z",
     "iopub.status.busy": "2023-09-22T09:48:39.403373Z",
     "iopub.status.idle": "2023-09-22T09:48:39.412510Z",
     "shell.execute_reply": "2023-09-22T09:48:39.412510Z",
     "shell.execute_reply.started": "2023-09-22T09:48:39.403373Z"
    }
   },
   "source": [
    "<font size = 6>LÃ©vy - ARMA - GARCH Risk Model Implement and its Evaluation - Prepare Data</font>\n",
    "<font size = 4><div style=\"text-align: right\"> Contributor: Haochen Jiang</div></font>\n",
    "<font size = 4><div style=\"text-align: right\"> May 3, 2022</div></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdafa896-4ea5-4e30-b7c4-28b38399a526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:30.490686Z",
     "iopub.status.busy": "2022-05-03T07:29:30.490686Z",
     "iopub.status.idle": "2022-05-03T07:29:30.503685Z",
     "shell.execute_reply": "2022-05-03T07:29:30.502685Z",
     "shell.execute_reply.started": "2022-05-03T07:29:30.490686Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab58c025-c684-4320-ba2e-8f8066543987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:31.066661Z",
     "iopub.status.busy": "2022-05-03T07:29:31.066661Z",
     "iopub.status.idle": "2022-05-03T07:29:32.066958Z",
     "shell.execute_reply": "2022-05-03T07:29:32.065958Z",
     "shell.execute_reply.started": "2022-05-03T07:29:31.066661Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import nlopt\n",
    "import scipy.stats\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "from scipy import integrate\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6969423-2432-4882-ba46-e5c57ae58d27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:32.760686Z",
     "iopub.status.busy": "2022-05-03T07:29:32.760686Z",
     "iopub.status.idle": "2022-05-03T07:29:32.771685Z",
     "shell.execute_reply": "2022-05-03T07:29:32.770685Z",
     "shell.execute_reply.started": "2022-05-03T07:29:32.760686Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adf_test(timeseries):\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "    \n",
    "def kpss_test(timeseries):\n",
    "    print ('Results of KPSS Test:')\n",
    "    kpsstest = kpss(timeseries, regression='c', nlags=\"auto\")\n",
    "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','#Lags Used'])\n",
    "    for key,value in kpsstest[3].items():\n",
    "        kpss_output['Critical Value (%s)'%key] = value\n",
    "    print (kpss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e360f9-4a81-4deb-b47c-54d79f1149aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:34.194222Z",
     "iopub.status.busy": "2022-05-03T07:29:34.194222Z",
     "iopub.status.idle": "2022-05-03T07:29:34.202221Z",
     "shell.execute_reply": "2022-05-03T07:29:34.201221Z",
     "shell.execute_reply.started": "2022-05-03T07:29:34.194222Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = 'D:\\\\Work\\\\'\n",
    "\n",
    "start = dt.datetime(2014, 1, 1)\n",
    "end = dt.datetime(2021, 12, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de75f5-ea1a-4db8-a95a-73172db5c5a2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db155c-3f73-49fb-a80e-a0b4d0e7677d",
   "metadata": {},
   "source": [
    "## Load Stock Information Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd3447-3ddb-4bc7-8d21-affd60d37870",
   "metadata": {},
   "source": [
    "<strong>Note:</strong><br>\n",
    "_snp_tickers_sectors.csv<br>\n",
    "It is found at https://en.wikipedia.org/wiki/List_of_S%26P_500_companies;<br>\n",
    "Last change was on April 21, 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cecbeb6-5197-4e6c-938f-c507cd17828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:35.477956Z",
     "iopub.status.busy": "2022-05-03T07:29:35.477956Z",
     "iopub.status.idle": "2022-05-03T07:29:35.499955Z",
     "shell.execute_reply": "2022-05-03T07:29:35.498954Z",
     "shell.execute_reply.started": "2022-05-03T07:29:35.477956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks in S&P500: 504\n"
     ]
    }
   ],
   "source": [
    "# Load S&P 500 Sector Information\n",
    "sector = pd.read_csv(path + \"Data\\\\stocks\\\\\" + \"_snp_tickers_sectors.csv\", index_col = 0)\n",
    "print(\"Number of stocks in S&P500: %d\" % sector.shape[0])\n",
    "# Make some necessary changes\n",
    "sector.rename(index = {\"BRK.B\": \"BRK-B\", \"BF.B\": \"BF-B\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04138e0-5450-4853-9cb0-24ef93f0c450",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e6a6c-36d4-4c08-b9e3-9d69b905f274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yf.download('^GSPC', progress=False).to_csv(path + \"Data\\\\\" + \"stocks\\\\\" + \"_SNP500.csv\")\n",
    "yf.download('^VIX', progress=False).to_csv(path + \"Data\\\\\" + \"_VIX.csv\")\n",
    "yf.download('^VVIX', progress=False).to_csv(path + \"Data\\\\\" + \"_VVIX.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4dec6f-9631-4758-8136-fb9bf4965610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Download Stocks Data\n",
    "bad_names = []\n",
    "not_enough_data_names = []\n",
    "for stock in list(sector.index):\n",
    "    try:       \n",
    "        stock_df = web.DataReader(stock, 'yahoo', start = dt.date(2012,1,1))\n",
    "        if stock_df.index[0] != dt.datetime(2012, 1, 3):\n",
    "            not_enough_data_names.append(stock)\n",
    "            print('Not enough data length in stock of %s.' % (stock))\n",
    "            sector.drop(sector[sector.index == stock].index, inplace = True)\n",
    "            print('Remove %s info from sector.' % (stock))\n",
    "        else:\n",
    "            stock_df['Name'] = stock\n",
    "            stock_df.to_csv(path + \"Data\\\\stocks\\\\\" + stock + \".csv\")\n",
    "    except:\n",
    "        bad_names.append(stock)\n",
    "        print('Data Not Found in Yahoo: %s.' % (stock))\n",
    "\n",
    "print(\"Stocks Data Downloading Ends.\")\n",
    "print(\"Failed stocks:\")\n",
    "print(bad_names)\n",
    "print(\"Not enough Data stocks:\")\n",
    "print(not_enough_data_names)\n",
    "print(\"Number of stocks now in S&P500: %d\" % sector.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67df7ff-f328-4467-b625-62b175a05d30",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dcec154-6eef-45e5-997e-eecc5d05fea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:38.538067Z",
     "iopub.status.busy": "2022-05-03T07:29:38.538067Z",
     "iopub.status.idle": "2022-05-03T07:29:38.549066Z",
     "shell.execute_reply": "2022-05-03T07:29:38.548065Z",
     "shell.execute_reply.started": "2022-05-03T07:29:38.538067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_size = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb53e31-9a72-4167-92f6-be7c11feec13",
   "metadata": {},
   "source": [
    "### Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e1a1a9e-a6de-4f0e-8c0f-50389f46972a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:39.251142Z",
     "iopub.status.busy": "2022-05-03T07:29:39.251142Z",
     "iopub.status.idle": "2022-05-03T07:29:39.347305Z",
     "shell.execute_reply": "2022-05-03T07:29:39.346304Z",
     "shell.execute_reply.started": "2022-05-03T07:29:39.251142Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load S&P 500 Data\n",
    "market = pd.read_csv(path + \"Data\\\\stocks\\\\\" + \"_SNP500.csv\", index_col = 0, parse_dates = True)\n",
    "market[\"Name\"] = \"^GSPC\"\n",
    "market = market[market.index < end][-(sample_size+1):]\n",
    "market['Return'] = market['Adj Close'].pct_change()\n",
    "market['Log Return'] = np.log(1 + market['Return'])\n",
    "market = market.dropna()\n",
    "# Load VIX Data\n",
    "vix = pd.read_csv(path + \"Data\\\\\" + \"_VIX.csv\", index_col = 0, parse_dates = True)\n",
    "vix[\"Name\"] = \"^VIX\"\n",
    "vix = vix[vix.index < end][-(sample_size+1):]\n",
    "vix['Return'] = vix['Adj Close'].pct_change()\n",
    "vix['Log Return'] = np.log(1 + vix['Return'])\n",
    "vix = vix.dropna()\n",
    "# Load VVIX Data\n",
    "vvix = pd.read_csv(path + \"Data\\\\\" + \"_VVIX.csv\", index_col = 0, parse_dates = True)\n",
    "vvix[\"Name\"] = \"^VVIX\"\n",
    "vvix = vvix[vvix.index < end][-(sample_size+1):]\n",
    "vvix['Return'] = vvix['Adj Close'].pct_change()\n",
    "vvix['Log Return'] = np.log(1 + vvix['Return'])\n",
    "vvix = vvix.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f742926-718b-4bfa-b270-7150653d1770",
   "metadata": {},
   "source": [
    "### Stocks Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8452387a-375d-4092-922c-699ca095f878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:39.879128Z",
     "iopub.status.busy": "2022-05-03T07:29:39.878068Z",
     "iopub.status.idle": "2022-05-03T07:29:44.571630Z",
     "shell.execute_reply": "2022-05-03T07:29:44.570445Z",
     "shell.execute_reply.started": "2022-05-03T07:29:39.879128Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Stocks prices Data\n",
    "stock_data = {}\n",
    "for stock in list(sector.index):\n",
    "    try:\n",
    "        stock_df = pd.read_csv(path + \"Data\\\\stocks\\\\\" + stock + \".csv\", index_col = 0, parse_dates = True)\n",
    "        stock_df = stock_df[stock_df.index < end][-(sample_size+1):]\n",
    "        # add return column\n",
    "        stock_df['Return'] = stock_df['Adj Close'].pct_change()\n",
    "        # add log return column\n",
    "        stock_df['Log Return'] = np.log(1 + stock_df['Return'])\n",
    "        stock_data[stock] = stock_df.dropna()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64887525-ac72-4123-86e3-3c322cb0874f",
   "metadata": {},
   "source": [
    "### Volatility Indices Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec86e3fb-d5e2-41c6-8486-d2c863f2f2a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T07:29:49.363051Z",
     "iopub.status.busy": "2022-05-03T07:29:49.363051Z",
     "iopub.status.idle": "2022-05-03T07:29:49.439944Z",
     "shell.execute_reply": "2022-05-03T07:29:49.439094Z",
     "shell.execute_reply.started": "2022-05-03T07:29:49.363051Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vxidx_data = {}\n",
    "name_list = [\"VXAPL\", \"VXAZN\", \"VXD\", \"VXGOG\", \"VXGS\", \"VXIBM\"]\n",
    "for idx in name_list:\n",
    "    idx_df = pd.read_csv(path + \"Data\\\\\" + idx + \".csv\", index_col = 0, parse_dates = True)\n",
    "    idx_df[\"Name\"] = idx\n",
    "    idx_df = idx_df[idx_df.index < end][-(sample_size+1):]\n",
    "    # add return column\n",
    "    idx_df['Return'] = idx_df['CLOSE'].pct_change()\n",
    "    # add log return column\n",
    "    idx_df['Log Return'] = np.log(1 + idx_df['Return'])\n",
    "    vxidx_data[idx] = idx_df.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
